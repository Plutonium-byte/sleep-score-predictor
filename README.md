## ğŸ’¤ Sleep Quality Prediction using Machine Learning

This project aims to predict an individualâ€™s **Quality of Sleep** based on their health and lifestyle habits using multiple machine learning models.
It demonstrates model training, evaluation, and containerized deployment using Docker and Flask.

---

## ğŸ“Š Dataset

**Source:** [Sleep Health and Lifestyle Dataset (Kaggle)](https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset)

The dataset contains information about individualsâ€™ **sleep habits, physical activity, stress levels, BMI category, and other lifestyle factors**.
The target variable is **`Quality of Sleep`**, which measures how well a person sleeps based on various lifestyle and health parameters.

Key features include:

* `Age`, `Gender`
* `Sleep Duration`, `Stress Level`
* `Physical Activity Level`, `BMI Category`
* `Occupation`, `Daily Steps`
* `Heart Rate`, `Blood Pressure`

---

## ğŸ§  Models Used

Four regression models were trained and compared:

1. **Linear Regression**
2. **DecisionTreeRegressor**
3. **RandomForestRegressor**
4. **XGBoost Regressor**

The models were evaluated using **Root Mean Squared Error (RMSE)**.

---

## âš™ï¸ Project Structure

```
â”œâ”€â”€ train.py          # Trains all models and saves the best one as model.bin
â”œâ”€â”€ predict.py        # Flask-based API (containerized with Docker) that serves predictions
â”œâ”€â”€ serve.py          # Sends requests to the Flask API (running in Docker) and retrieves predictions
â”œâ”€â”€ notebook.ipynb    # Exploratory Data Analysis and experimentation
â”œâ”€â”€ pyproject.toml    # Project configuration and dependencies (managed with uv)
â”œâ”€â”€ requirements.txt  # Optional dependency export
â”œâ”€â”€ dataset.csv       # Sleep Health and Lifestyle dataset (from Kaggle)
â”œâ”€â”€ uv.lock           # Locked dependency versions for reproducibility 
â”œâ”€â”€ Dockerfile        # Defines the container for running predict.py
â”œâ”€â”€ model.bin         # Saved trained model used by predict.py
â”œâ”€â”€ .python-version   # Specifies Python version used in the project       
â””â”€â”€ README.md         # Project documentation
```

---

## ğŸ³ Docker Integration

* `predict.py` is **containerized using Docker** and exposes a **Flask API** endpoint for predictions.
* When `service.py` is run locally, it sends a **POST request** to the Flask API in the container to get predictions.
* The container loads `model.bin` (generated by `train.py`) to make predictions and returns the result in JSON format.

---

## ğŸ“ˆ Model Performance

Below are placeholders for model performance comparison bar plots.

### ğŸ”¹ Normal Train (Partial Training Dataset (60%) )

<img width="1390" height="490" alt="download" src="https://github.com/user-attachments/assets/86f57297-e96a-40da-8d71-336d30bd8158" />

> ğŸ† **Best Model:** `XGBoost`

---

### ğŸ”¹ Full Train (Complete Dataset (80%) )

<img width="1390" height="490" alt="download" src="https://github.com/user-attachments/assets/35380b66-8b10-4402-b06f-4ebb98feef13" />

> ğŸ† **Best Model:** `DecisionTreeRegressor`

---

## ğŸ§° Technologies Used

* **Python**
* **Flask**
* **NumPy**
* **Pandas**
* **Matplotlib**
* **Scikit-learn**
* **XGBoost**
* **Docker**
* **uv** (for dependency and environment management)

---

## ğŸ“ Evaluation Metric

The models were evaluated using **Root Mean Squared Error (RMSE)**:

RMSE = sqrt( (1/n) * Î£(yáµ¢ - Å·áµ¢)Â² )

Lower RMSE values indicate better model performance.

---

## ğŸš€ How to Run

### 1. **Set up the environment with uv**

Initialize and install all dependencies:

```bash
uv sync
```

---

### 2. **Train and Save the model**

```bash
python train.py
```

### 3. **Run the Docker container**

```bash
docker build -t sleep-predictor .
docker run -it -p 9696:9696 sleep-predictor
```

### 4. **Start the service (Flask client)**

```bash
python serve.py
```

---

## ğŸ“ Notes

* The model performance varies between **normal training** and **full training** datasets.
* Different models performed best in each case, showcasing the importance of training size and feature interactions.
* The **Flask API** acts as the communication layer between the containerized model (`predict.py`) and the local service (`serve.py`).
* All project dependencies are managed using **uv** for clean, reproducible environments.
